# ğŸ«€ Archive Model Script Aggregation Workflow

## Overview

The Archive Model serves as the **master of the scrolls** - the central repository for all constellation scripting knowledge. This workflow implements a comprehensive script aggregation system that collects, deduplicates, and manages scripts from across all FourTwenty Analytics stars.

## Philosophy

> *"Breathes life into the constellation by maintaining memory, seeds, and history. Think master of the scrolls."*

The Archive Model's script aggregation embodies the constellation's memory by:
- ğŸ“œ **Collecting** all scripting knowledge from every star
- ğŸ”„ **Deduplicating** to prevent redundancy while preserving variants
- ğŸ’¾ **Preserving** historical versions through timestamped backups
- ğŸ›¡ï¸ **Protecting** against data loss with restoration capabilities

## Architecture

### Files Created

```
archive-model/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ aggregate-scripts.sh         # Core aggregation logic
â”‚   â”œâ”€â”€ validate-scripts.sh         # Collection validation and coverage analysis
â”‚   â”œâ”€â”€ restore-scripts.sh          # Backup management and restoration
â”‚   â”œâ”€â”€ README_SCRIPT_AGGREGATION.md # This documentation
â”‚   â””â”€â”€ SCRIPT_WORKFLOW_GUIDE.md    # Quick reference guide
â”œâ”€â”€ data/
â”‚   â””â”€â”€ script_backups/
â”‚       â”œâ”€â”€ YYYYMMDDTHHMMSSZ/       # Timestamped backups
â”‚       â””â”€â”€ YYYYMMDDTHHMMSSZ-pre-restore/ # Pre-restoration backups
â””â”€â”€ signals/
    â””â”€â”€ latest.json                  # Broadcast aggregation status
```

### Aggregation Process

The workflow follows a **four-phase approach**:

#### Phase 1: Discovery and Collection
- ğŸ” Scans all `*-model` directories in constellation
- ğŸ“ Identifies modules with `scripts/` directories  
- ğŸ“„ Collects all non-hidden files from each star's scripts
- ğŸ·ï¸ Adds source metadata headers for traceability

#### Phase 2: Current State Preservation
- ğŸ—ƒï¸ Backs up existing archive-model scripts
- ğŸ›¡ï¸ Preserves current state before any modifications
- ğŸ“Š Counts and catalogs existing scripts

#### Phase 3: Intelligent Deduplication
- ğŸ” Uses SHA-256 hashing for content comparison
- ğŸ”€ Detects identical files across stars
- ğŸ“ Creates merged versions for content differences
- âœ¨ Maintains both sources when conflicts exist

#### Phase 4: Deployment and Backup
- ğŸ’¾ Creates timestamped backup of current state
- ğŸ”„ Deploys deduplicated script collection
- âœ… Sets appropriate file permissions
- ğŸ“¡ Broadcasts completion status

## Usage

### Manual Aggregation

```bash
cd archive-model

# Run complete aggregation workflow
./scripts/aggregate-scripts.sh

# Validate the aggregated collection
./scripts/validate-scripts.sh

# View aggregation coverage and statistics
./scripts/validate-scripts.sh
```

### Backup Management

```bash
# List available backups
./scripts/restore-scripts.sh list

# Restore from specific backup
./scripts/restore-scripts.sh restore 20250923T120000Z

# Clean old backups (older than 30 days)
./scripts/restore-scripts.sh clean

# Clean backups older than 7 days
./scripts/restore-scripts.sh clean 7
```

## Output Structure

### Source Tracking
Every aggregated script includes metadata headers:

```bash
# Source: signal-model/scripts/aggregate-constellation.sh  
# Collected by Archive Model Script Aggregator
# Original path: /path/to/signal-model/scripts/aggregate-constellation.sh

#!/usr/bin/env bash
# Original script content follows...
```

### Conflict Resolution
When multiple stars have scripts with the same name but different content:

```bash
# MERGED FILE: Multiple sources detected
# Sources: archive-model (current) + constellation
# Merged by Archive Model Script Aggregator

# === SOURCE 1: archive-model (current) ===
# Original archive version...

# === SOURCE 2: constellation ===  
# Alternative constellation version...
```

### Aggregation Statistics
Each run produces detailed statistics:

```json
{
  "aggregation_stats": {
    "stars_processed": 15,
    "scripts_collected": 42,
    "scripts_deployed": 38,
    "duplicates_found": 4,
    "backup_location": "data/script_backups/20250923T120000Z"
  }
}
```

## Validation & Coverage

### Script Collection Health
The validator checks:
- âœ… File executability and permissions
- ğŸ“ Source attribution and traceability  
- ğŸ“ File sizes and basic structure
- ğŸ”§ Shell script shebangs and headers

### Constellation Coverage
Analyzes coverage across all stars:
- â­ Total stars with scripts directories
- ğŸ“œ Scripts per star mapping
- âš ï¸ Missing aggregations detection
- ğŸ“Š Coverage percentage reporting

### Backup Integrity
Monitors backup ecosystem:
- ğŸ’¾ Available backup timestamps
- ğŸ•’ Most recent backup dates
- ğŸ“ Backup file counts and sizes
- ğŸ§¹ Cleanup recommendations

## Integration with Constellation

### Discovery Logic
Automatically finds constellation stars:
```bash
# Matches directories: *-model with scripts/ subdirectory
# Excludes: archive-model (self) 
# Processes: All files except hidden (.*)
```

### Star Requirements
For scripts to be aggregated:
```
<star-name>-model/
â””â”€â”€ scripts/
    â”œâ”€â”€ script1.sh     # Will be collected
    â”œâ”€â”€ script2.py     # Will be collected  
    â”œâ”€â”€ README.md      # Will be collected
    â””â”€â”€ .hidden        # Will be ignored
```

### Downstream Integration
The aggregated collection enables:
- ğŸ” **Cross-constellation script analysis** - Find patterns and duplications
- ğŸ› ï¸ **Centralized tooling access** - Single location for all constellation scripts
- ğŸ“Š **Script evolution tracking** - Historical versions through backups
- ğŸš€ **Deployment standardization** - Consistent scripting patterns
- ğŸ”„ **Knowledge preservation** - Prevents script loss across stars

## Safety Mechanisms

### Backup Protection
- ğŸ’¾ **Automatic backups** before every aggregation
- ğŸ•’ **Timestamped preservation** with YYYYMMDDTHHMMSSZ format  
- ğŸ›¡ï¸ **Pre-restoration backups** before any recovery operation
- ğŸ§¹ **Configurable cleanup** to manage storage usage

### Content Preservation
- ğŸ  **Native script priority** - Archive scripts take precedence
- ğŸ”€ **Merge conflict handling** - Creates combined versions when needed
- ğŸ“ **Source attribution** - Every file tracks its origin
- âœ¨ **Permission maintenance** - Executable bits preserved

### Error Handling
- ğŸ”„ **Graceful failures** - Individual star failures don't stop aggregation
- ğŸ“Š **Detailed logging** - Complete operation tracking
- âœ… **Validation integration** - Built-in health checks
- ğŸš¨ **Signal broadcasting** - Status updates to constellation

## Maintenance

### Regular Operations
```bash
# Weekly aggregation to capture new scripts
./scripts/aggregate-scripts.sh

# Monthly validation to check coverage
./scripts/validate-scripts.sh  

# Quarterly backup cleanup
./scripts/restore-scripts.sh clean 90
```

### Troubleshooting

| Issue | Diagnosis | Solution |
|-------|-----------|----------|
| No scripts collected | Check constellation star structure | Verify `*-model/scripts/` directories exist |
| Permission errors | File ownership issues | Run `chmod +x scripts/*.sh` |
| Backup failures | Disk space or permissions | Check `data/` directory writability |
| Missing coverage | Stars not discovered | Ensure stars follow `*-model` naming |
| Hash conflicts | SHA tools unavailable | Install `shasum` or `sha256sum` |

### Recovery Procedures
```bash
# Emergency restoration to last known good state
./scripts/restore-scripts.sh list
./scripts/restore-scripts.sh restore <latest-backup>

# Validate restoration success  
./scripts/validate-scripts.sh

# Re-run aggregation if needed
./scripts/aggregate-scripts.sh
```

## Schema Conformance

All operations maintain constellation standards:
- Scripts conform to existing executable patterns
- Signals broadcast using `latest.schema.yml` structure  
- Directory organization follows module standards
- Metadata headers provide full traceability

The Archive Model's script aggregation ensures that the constellation's scripting knowledge is never lost, always accessible, and continuously evolving - truly serving as the **master of the scrolls** for the entire FourTwenty Analytics ecosystem.